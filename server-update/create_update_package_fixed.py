#!/usr/bin/env python3
"""
Script per creare pacchetti di aggiornamento autoinstallanti per ArmNAS
Genera file .run che contengono tutto il necessario per l'aggiornamento
"""

import os
import sys
import json
import shutil
import tarfile
import hashlib
import argparse
import tempfile
from datetime import datetime
from pathlib import Path

class UpdatePackageBuilder:
    def __init__(self, version, output_dir="./updates"):
        self.version = version
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.temp_dir = None
        
    def create_package(self, source_dir=".", changelog=None, critical=False):
        """Crea il pacchetto di aggiornamento"""
        print(f"üöÄ Creazione pacchetto aggiornamento v{self.version}")
        
        # Verifica prerequisiti
        if not self._check_prerequisites(source_dir):
            return None
        
        # Crea directory temporanea
        self.temp_dir = tempfile.mkdtemp(prefix="armnas_update_")
        print(f"üìÅ Directory temporanea: {self.temp_dir}")
        
        try:
            # 1. Prepara i file
            package_dir = Path(self.temp_dir) / "package"
            package_dir.mkdir()
            
            self._copy_source_files(source_dir, package_dir)
            self._create_metadata(package_dir, changelog, critical)
            self._create_install_script(package_dir)
            
            # 2. Crea l'archivio
            archive_path = self._create_archive(package_dir)
            
            # 3. Crea il file .run autoinstallante
            run_file = self._create_run_file(archive_path)
            
            print(f"‚úÖ Pacchetto creato: {run_file}")
            return run_file
            
        finally:
            # Pulisci directory temporanea
            if self.temp_dir and os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
    
    def _check_prerequisites(self, source_dir):
        """Verifica che tutti i prerequisiti siano soddisfatti"""
        print("üîç Verifica prerequisiti...")
        source_path = Path(source_dir)
        
        # Verifica che la directory sorgente esista
        if not source_path.exists():
            print(f"‚ùå Directory sorgente non trovata: {source_dir}")
            return False
        
        # Verifica che esista almeno il backend
        backend_dir = source_path / "backend"
        if not backend_dir.exists():
            print("‚ùå Directory backend non trovata")
            return False
        
        # Verifica file essenziali del backend
        essential_files = ["main.py", "requirements.txt"]
        for file in essential_files:
            if not (backend_dir / file).exists():
                print(f"‚ùå File essenziale mancante: backend/{file}")
                return False
        
        # Verifica frontend (opzionale ma consigliato)
        frontend_dist = source_path / "frontend" / "dist"
        frontend_src = source_path / "frontend"
        
        if not frontend_dist.exists():
            if frontend_src.exists():
                print("‚ö†Ô∏è  Frontend non compilato - verr√† tentata la compilazione automatica")
            else:
                print("‚ö†Ô∏è  Directory frontend non trovata - il pacchetto non includer√† il frontend")
        
        print("‚úÖ Prerequisiti verificati")
        return True
    
    def _copy_source_files(self, source_dir, package_dir):
        """Copia i file sorgente nel pacchetto"""
        print("üì¶ Copia file sorgente...")
        source_path = Path(source_dir)
        print(f"  üìÅ Directory sorgente: {source_path.absolute()}")
        print(f"  üìÅ Directory pacchetto: {package_dir.absolute()}")
        
        # Backend
        backend_src = source_path / "backend"
        if backend_src.exists():
            print(f"  üêç Backend: {backend_src} -> {package_dir / 'backend'}")
            backend_dst = package_dir / "backend"
            
            # Conta i file prima della copia
            backend_files = list(backend_src.rglob('*'))
            print(f"    üìä File backend da copiare: {len(backend_files)}")
            
            shutil.copytree(backend_src, backend_dst, ignore=shutil.ignore_patterns(
                '__pycache__', '*.pyc', '*.pyo', '.git*', 'venv', '.env*', 'armnas.db'
            ))
            
            # Verifica copia
            copied_files = list(backend_dst.rglob('*'))
            print(f"    ‚úÖ File backend copiati: {len(copied_files)}")
        else:
            print(f"  ‚ùå Directory backend non trovata: {backend_src}")
        
        # Frontend - Copia tutto il codice sorgente per ricompilazione sul server
        frontend_src = source_path / "frontend"
        if frontend_src.exists():
            print(f"  üåê Frontend: {frontend_src} -> {package_dir / 'frontend'}")
            frontend_dst = package_dir / "frontend"
            
            # Conta i file prima della copia (escludendo node_modules)
            frontend_files = [f for f in frontend_src.rglob('*') if 'node_modules' not in f.parts]
            print(f"    üìä File frontend da copiare: {len(frontend_files)}")
            
            # Copia tutto il frontend escludendo node_modules e dist
            shutil.copytree(frontend_src, frontend_dst, ignore=shutil.ignore_patterns(
                'node_modules', '.git*', '*.log', '.DS_Store', 'Thumbs.db'
            ))
            
            # Verifica copia
            copied_files = list(frontend_dst.rglob('*'))
            print(f"    ‚úÖ File frontend copiati: {len(copied_files)}")
            
            # Se esiste una build gi√† compilata, copiala come fallback
            frontend_dist = source_path / "frontend" / "dist"
            if frontend_dist.exists():
                print("  üì¶ Incluso anche frontend precompilato come fallback...")
                dist_files = list(frontend_dist.rglob('*'))
                print(f"    üìä File dist da copiare: {len(dist_files)}")
                
                dist_dst = frontend_dst / "dist"
                if dist_dst.exists():
                    shutil.rmtree(dist_dst)
                shutil.copytree(frontend_dist, dist_dst)
        else:
            print(f"  ‚ùå Directory frontend non trovata: {frontend_src}")
        
        # Script di sistema - COPIA TUTTI gli script .sh dalla root E da scripts/
        print("  üìú Copia script di sistema...")
        script_count = 0
        
        # Script dalla root del progetto
        for script_file in source_path.glob("*.sh"):
            print(f"    üìú {script_file.name} (root)")
            shutil.copy2(script_file, package_dir)
            # Rendi eseguibile
            os.chmod(package_dir / script_file.name, 0o755)
            script_count += 1
        
        # Script dalla directory scripts/
        scripts_dir = source_path / "scripts"
        if scripts_dir.exists():
            for script_file in scripts_dir.glob("*.sh"):
                print(f"    üìú {script_file.name} (scripts/)")
                shutil.copy2(script_file, package_dir)
                # Rendi eseguibile
                os.chmod(package_dir / script_file.name, 0o755)
                script_count += 1
        
        print(f"    ‚úÖ Script copiati: {script_count}")
        
        # File di configurazione dalla root
        for conf_file in source_path.glob("*.conf"):
            print(f"  ‚öôÔ∏è  {conf_file.name}")
            shutil.copy2(conf_file, package_dir)
        
        # File di configurazione dalla directory config/
        config_dir = source_path / "config"
        if config_dir.exists():
            print("  üìÅ Copia file da config/...")
            for conf_file in config_dir.glob("*.conf"):
                print(f"    ‚öôÔ∏è  {conf_file.name}")
                shutil.copy2(conf_file, package_dir)
            
            # File servizi systemd da config/
            for service_file in config_dir.glob("*.service"):
                print(f"    üîß {service_file.name}")
                shutil.copy2(service_file, package_dir)
            
            # Docker compose file da config/
            for compose_file in config_dir.glob("docker-compose*.yml"):
                print(f"    üê≥ {compose_file.name}")
                shutil.copy2(compose_file, package_dir)
        
        # Docker compose file dalla root (per retrocompatibilit√†)
        for compose_file in source_path.glob("docker-compose*.yml"):
            print(f"  üê≥ {compose_file.name}")
            shutil.copy2(compose_file, package_dir)
        
        # File VERSION
        version_file = source_path / "VERSION"
        if version_file.exists():
            print(f"  üìã VERSION file")
            shutil.copy2(version_file, package_dir)
        else:
            # Crea il file VERSION con la versione del pacchetto
            print(f"  üìã Creazione VERSION file con versione {self.version}")
            with open(package_dir / "VERSION", 'w') as f:
                f.write(self.version + '\n')
    
    def _create_metadata(self, package_dir, changelog, critical):
        """Crea il file metadata.json"""
        print("üìã Creazione metadata...")
        
        metadata = {
            "version": self.version,
            "timestamp": datetime.now().isoformat(),
            "critical": critical,
            "changelog": changelog or f"Aggiornamento alla versione {self.version}",
            "files": self._get_file_list(package_dir)
        }
        
        metadata_file = package_dir / "metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    def _get_file_list(self, package_dir):
        """Ottiene la lista dei file nel pacchetto"""
        files = []
        for root, dirs, filenames in os.walk(package_dir):
            for filename in filenames:
                if filename == "metadata.json":
                    continue
                file_path = Path(root) / filename
                rel_path = file_path.relative_to(package_dir)
                files.append(str(rel_path))
        return files
    
    def _create_install_script(self, package_dir):
        """Crea lo script di aggiornamento semplificato"""
        print("üìú Creazione script di aggiornamento...")
        
        install_script = '''#!/bin/bash
set -e

# Script di aggiornamento ArmNAS
INSTALL_DIR="/opt/armnas"
BACKUP_DIR="/opt/armnas/backups"
SERVICE_NAME="armnas-backend"
NGINX_SERVICE="nginx"

echo "üöÄ Aggiornamento ArmNAS v$(cat metadata.json | grep version | cut -d'"' -f4)"

# Funzione per logging
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# Funzione per gestire errori
handle_error() {
    log "‚ùå ERRORE: $1"
    exit 1
}

# Verifica privilegi root
if [[ $EUID -ne 0 ]]; then
    handle_error "Questo script deve essere eseguito come root"
fi

# Verifica che ArmNAS sia gi√† installato
if [[ ! -d "$INSTALL_DIR" ]]; then
    handle_error "ArmNAS non sembra essere installato in $INSTALL_DIR"
fi

# Parsing argomenti
AUTO_INSTALL="false"
BACKUP_PATH=""

log "üîç Argomenti ricevuti: $@"

while [[ $# -gt 0 ]]; do
    case $1 in
        --auto)
            AUTO_INSTALL="true"
            log "‚úÖ Modalit√† AUTO attivata"
            shift
            ;;
        --backup)
            BACKUP_PATH="$2"
            log "üíæ Backup path personalizzato: $BACKUP_PATH"
            shift 2
            ;;
        *)
            log "‚ö†Ô∏è  Argomento sconosciuto ignorato: $1"
            shift
            ;;
    esac
done

log "üìä AUTO_INSTALL=$AUTO_INSTALL"

# Conferma aggiornamento (se non auto)
if [[ "$AUTO_INSTALL" != "true" ]]; then
    read -p "Procedere con l'aggiornamento? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log "Aggiornamento annullato"
        exit 0
    fi
fi

log "üìã Caricamento metadata..."
if [[ ! -f "metadata.json" ]]; then
    handle_error "File metadata.json non trovato"
fi

VERSION=$(cat metadata.json | grep -o '"version"[[:space:]]*:[[:space:]]*"[^"]*"' | cut -d'"' -f4 | tr -d '\n\r')
log "Versione da installare: $VERSION"

# Leggi versione precedente installata
PREVIOUS_VERSION=""
if [[ -f "$INSTALL_DIR/VERSION" ]]; then
    PREVIOUS_VERSION=$(cat "$INSTALL_DIR/VERSION" | tr -d '\n\r' | head -1)
    log "Versione precedente: $PREVIOUS_VERSION"
else
    log "Versione precedente: sconosciuta (prima installazione o pre-VERSION)"
    PREVIOUS_VERSION="0.0.0"
fi

# Crea backup automatico
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
AUTO_BACKUP_PATH="$BACKUP_DIR/backup_pre_update_${VERSION}_${TIMESTAMP}.tar.gz"

log "üíæ Creazione backup automatico..."
mkdir -p "$BACKUP_DIR"

# Ferma temporaneamente i servizi per evitare modifiche ai file durante il backup
log "‚è∏Ô∏è  Arresto temporaneo servizi per backup sicuro..."
BACKEND_WAS_RUNNING=false
NGINX_WAS_RUNNING=false

if systemctl is-active --quiet "$SERVICE_NAME" 2>/dev/null; then
    BACKEND_WAS_RUNNING=true
    systemctl stop "$SERVICE_NAME" || log "‚ö†Ô∏è  Impossibile fermare temporaneamente $SERVICE_NAME"
fi

if systemctl is-active --quiet "$NGINX_SERVICE" 2>/dev/null; then
    NGINX_WAS_RUNNING=true
    systemctl stop "$NGINX_SERVICE" || log "‚ö†Ô∏è  Impossibile fermare temporaneamente $NGINX_SERVICE"
fi

# Attendi che i processi si fermino completamente
sleep 2

# Crea il backup escludendo file che potrebbero cambiare
tar -czf "$AUTO_BACKUP_PATH" \
    -C "$(dirname "$INSTALL_DIR")" \
    --exclude="$(basename "$INSTALL_DIR")/backend/__pycache__" \
    --exclude="$(basename "$INSTALL_DIR")/backend/*.pyc" \
    --exclude="$(basename "$INSTALL_DIR")/backend/*.pyo" \
    --exclude="$(basename "$INSTALL_DIR")/backend/venv" \
    --exclude="$(basename "$INSTALL_DIR")/backend/*.log" \
    --exclude="$(basename "$INSTALL_DIR")/backend/logs" \
    --exclude="$(basename "$INSTALL_DIR")/backups" \
    --exclude="$(basename "$INSTALL_DIR")/tmp" \
    --exclude="$(basename "$INSTALL_DIR")/.git*" \
    "$(basename "$INSTALL_DIR")" || handle_error "Errore nella creazione del backup"

# Riavvia i servizi se erano attivi
if [ "$BACKEND_WAS_RUNNING" = true ]; then
    systemctl start "$SERVICE_NAME" || log "‚ö†Ô∏è  Impossibile riavviare $SERVICE_NAME"
fi

if [ "$NGINX_WAS_RUNNING" = true ]; then
    systemctl start "$NGINX_SERVICE" || log "‚ö†Ô∏è  Impossibile riavviare $NGINX_SERVICE"
fi

log "‚úÖ Backup creato: $AUTO_BACKUP_PATH"

# Crea backup aggiuntivo se richiesto
if [[ -n "$BACKUP_PATH" ]]; then
    log "üíæ Creazione backup aggiuntivo in $BACKUP_PATH..."
    mkdir -p "$(dirname "$BACKUP_PATH")"
    cp "$AUTO_BACKUP_PATH" "$BACKUP_PATH" || handle_error "Errore nella copia del backup"
fi

# NON fermiamo i servizi durante l'aggiornamento
# I file verranno sovrascritti e i servizi riavviati dopo il reboot
log "‚ÑπÔ∏è  Aggiornamento file in corso (servizi rimangono attivi)..."

# Backup configurazioni critiche
log "üíæ Backup configurazioni..."
TEMP_CONFIG_DIR="/tmp/armnas_config_backup_$$"
mkdir -p "$TEMP_CONFIG_DIR"

# Backup configurazione backend se esiste
if [[ -f "$INSTALL_DIR/backend/config.py" ]]; then
    cp "$INSTALL_DIR/backend/config.py" "$TEMP_CONFIG_DIR/"
fi

# Backup database se esiste
if [[ -f "$INSTALL_DIR/backend/armnas.db" ]]; then
    cp "$INSTALL_DIR/backend/armnas.db" "$TEMP_CONFIG_DIR/"
fi

# Aggiorna Backend
if [[ -d "backend" ]]; then
    log "üêç Aggiornamento backend..."
    # Mantieni l'ambiente virtuale se esiste
    if [[ -d "$INSTALL_DIR/backend/venv" ]]; then
        log "  üì¶ Mantenimento ambiente virtuale..."
        mv "$INSTALL_DIR/backend/venv" "$TEMP_CONFIG_DIR/"
    fi
    
    # Copia nuovi file backend
    cp -r backend/* "$INSTALL_DIR/backend/" || handle_error "Errore nell'aggiornamento del backend"
    
    # Ripristina ambiente virtuale
    if [[ -d "$TEMP_CONFIG_DIR/venv" ]]; then
        mv "$TEMP_CONFIG_DIR/venv" "$INSTALL_DIR/backend/"
    fi
    
    # Aggiorna dipendenze se necessario
    if [[ -f "$INSTALL_DIR/backend/requirements.txt" && -d "$INSTALL_DIR/backend/venv" ]]; then
        log "  üìö Aggiornamento dipendenze Python..."
        source "$INSTALL_DIR/backend/venv/bin/activate"
        pip install --upgrade pip
        pip install -r "$INSTALL_DIR/backend/requirements.txt" || log "‚ö†Ô∏è  Errore nell'aggiornamento delle dipendenze"
        deactivate
    fi
fi

# Aggiorna Frontend
if [[ -d "frontend" ]]; then
    log "üåê Aggiornamento frontend..."
    
    # Verifica se esiste frontend/dist precompilato
    if [[ -d "frontend/dist" && -f "frontend/dist/index.html" ]]; then
        log "  ‚úÖ Trovato frontend precompilato"
        
        # Backup del frontend esistente
        if [[ -d "$INSTALL_DIR/frontend" ]]; then
            log "  üíæ Backup frontend esistente..."
            rm -rf "$INSTALL_DIR/frontend.backup"
            mv "$INSTALL_DIR/frontend" "$INSTALL_DIR/frontend.backup"
        fi
        
        # Crea directory frontend
        mkdir -p "$INSTALL_DIR/frontend"
        
        # Copia SOLO i file compilati da frontend/dist/ a /opt/armnas/frontend/
        log "  üì¶ Copia frontend compilato..."
        cp -r frontend/dist/* "$INSTALL_DIR/frontend/" || handle_error "Errore nella copia del frontend"
        
        log "  ‚úÖ Frontend aggiornato (precompilato)"
    else
        log "  ‚ö†Ô∏è  Frontend precompilato non trovato, provo a compilare sul server..."
        
        # Backup del frontend esistente
        if [[ -d "$INSTALL_DIR/frontend" ]]; then
            log "  üíæ Backup frontend esistente..."
            rm -rf "$INSTALL_DIR/frontend.backup"
            mv "$INSTALL_DIR/frontend" "$INSTALL_DIR/frontend.backup"
        fi
        
        # Copia codice sorgente in directory temporanea
        TEMP_FRONTEND_DIR="/tmp/armnas_frontend_build_$$"
        log "  üìÅ Copia codice sorgente in $TEMP_FRONTEND_DIR..."
        cp -r frontend "$TEMP_FRONTEND_DIR" || handle_error "Errore nella copia del frontend"
        
        cd "$TEMP_FRONTEND_DIR"
        
        # Prova a compilare
        if command -v npm >/dev/null 2>&1; then
            log "  üì¶ Installazione dipendenze npm..."
            npm install --production=false || {
                log "  ‚ùå Errore installazione dipendenze"
                # Ripristina backup
                if [[ -d "$INSTALL_DIR/frontend.backup" ]]; then
                    mv "$INSTALL_DIR/frontend.backup" "$INSTALL_DIR/frontend"
                fi
                rm -rf "$TEMP_FRONTEND_DIR"
                handle_error "Impossibile installare dipendenze npm"
            }
            
            log "  üèóÔ∏è  Build di produzione..."
            npm run build || {
                log "  ‚ùå Errore nella build"
                # Ripristina backup
                if [[ -d "$INSTALL_DIR/frontend.backup" ]]; then
                    mv "$INSTALL_DIR/frontend.backup" "$INSTALL_DIR/frontend"
                fi
                rm -rf "$TEMP_FRONTEND_DIR"
                handle_error "Impossibile compilare il frontend"
            }
            
            # Copia i file compilati
            if [[ -d "dist" && -f "dist/index.html" ]]; then
                log "  üì¶ Copia frontend compilato..."
                mkdir -p "$INSTALL_DIR/frontend"
                cp -r dist/* "$INSTALL_DIR/frontend/" || handle_error "Errore nella copia del frontend compilato"
                log "  ‚úÖ Frontend compilato e installato"
            else
                log "  ‚ùå Build non ha prodotto file dist/"
                # Ripristina backup
                if [[ -d "$INSTALL_DIR/frontend.backup" ]]; then
                    mv "$INSTALL_DIR/frontend.backup" "$INSTALL_DIR/frontend"
                fi
                rm -rf "$TEMP_FRONTEND_DIR"
                handle_error "Frontend non compilato correttamente"
            fi
        else
            log "  ‚ùå npm non disponibile"
            # Ripristina backup
            if [[ -d "$INSTALL_DIR/frontend.backup" ]]; then
                mv "$INSTALL_DIR/frontend.backup" "$INSTALL_DIR/frontend"
            fi
            rm -rf "$TEMP_FRONTEND_DIR"
            handle_error "npm non disponibile per compilare il frontend"
        fi
        
        # Pulizia
        cd - >/dev/null
        rm -rf "$TEMP_FRONTEND_DIR"
    fi
    
    # Rimuovi backup se tutto ok
    rm -rf "$INSTALL_DIR/frontend.backup"
else
    log "  ‚ö†Ô∏è  Nessun aggiornamento frontend nel pacchetto"
fi

# Aggiorna Script di sistema
log "üìú Aggiornamento script..."
for script in *.sh; do
    if [[ -f "$script" ]]; then
        cp "$script" "$INSTALL_DIR/" || handle_error "Errore nell'aggiornamento degli script"
        chmod +x "$INSTALL_DIR/$script"
    fi
done

# Nota: Gli script sono copiati in /opt/armnas/ ma NON eseguiti automaticamente.
# Disponibili per esecuzione manuale se necessario:
#   - disable-zfs-auto-snapshot.sh: disabilita snapshot automatiche ZFS (eseguito solo in install.sh)
#   - fix-docker-storage-driver.sh: cambia Docker da ZFS a overlay2 (utile per sistemi pre-v0.2.7)
#   - fix-nginx-systemd.sh: risolve problema blocco nginx su systemd (solo uso manuale)
# 
# v0.2.7 aggiorna automaticamente:
#   - config/armnas-auto-update.service (rimuove Before=nginx.service)
# 
# Dalla v0.2.7 in poi, nuove installazioni hanno gi√†:
#   - Docker configurato con overlay2
#   - Snapshot ZFS disabilitate
#   - armnas-auto-update.service corretto

# Copia anche updater_service.py se esiste
if [[ -f "backend/updater_service.py" ]]; then
    log "üîÑ Aggiornamento updater service..."
    cp "backend/updater_service.py" "$INSTALL_DIR/backend/" || handle_error "Errore nell'aggiornamento updater service"
    log "  ‚úÖ Updater service aggiornato"
fi

# Aggiorna Configurazioni
log "‚öôÔ∏è  Aggiornamento configurazioni..."
for conf in *.conf; do
    if [[ -f "$conf" ]]; then
        # Backup configurazione esistente
        if [[ -f "$INSTALL_DIR/$conf" ]]; then
            cp "$INSTALL_DIR/$conf" "$TEMP_CONFIG_DIR/$conf.old"
        fi
        cp "$conf" "$INSTALL_DIR/" || handle_error "Errore nell'aggiornamento delle configurazioni"
    fi
done

# Aggiorna servizi systemd (file .service)
log "üîß Aggiornamento servizi systemd..."
for service in *.service; do
    if [[ -f "$service" ]]; then
        log "  Aggiornamento servizio: $service"
        # Backup servizio esistente
        if [[ -f "/etc/systemd/system/$service" ]]; then
            cp "/etc/systemd/system/$service" "$TEMP_CONFIG_DIR/$service.old"
        fi
        # Copia nuovo servizio
        cp "$service" "/etc/systemd/system/" || log "‚ö†Ô∏è  Errore nell'aggiornamento di $service"
    fi
done

# ========================================================================
# FIX SPECIFICI PER VERSIONE
# ========================================================================
# REGOLE per aggiungere fix:
# 1. SEMPRE idempotenti (controllare prima se necessario)
# 2. Includere numero versione nel commento (es. "Fix v0.2.7")
# 3. Non rimuovere mai fix vecchi - lasciarli qui (sono idempotenti)
# 4. Fix futuri possono essere applicati a tutti perch√© controllano condizioni
#
# ESEMPIO di fix idempotente:
#   if [[ condizione_che_richiede_fix ]]; then
#       log "üîß Fix vX.Y.Z: descrizione..."
#       applica_fix
#   else
#       log "‚úì Sistema gi√† corretto (fix vX.Y.Z non necessario)"
#   fi
# ========================================================================

# Fix v0.2.7: Rimozione override nginx
# Idempotente: controlla se esiste prima di rimuovere
if [[ -f "/etc/systemd/system/nginx.service.d/override.conf" ]]; then
    log "  üîß Fix v0.2.7: Rimozione override nginx (da v$PREVIOUS_VERSION)..."
    rm -f "/etc/systemd/system/nginx.service.d/override.conf"
    # Rimuovi directory se vuota
    rmdir "/etc/systemd/system/nginx.service.d" 2>/dev/null || true
    log "  ‚úÖ Override nginx rimosso"
else
    log "  ‚úì Nginx gi√† corretto (nessun override)"
fi

# ========================================================================
# AGGIUNGI NUOVI FIX QUI SOTTO (sempre idempotenti!)
# ========================================================================

# Fix v0.3.0: Pulizia vecchi dataset Docker ZFS (causano snapshot e rallentamenti)
# Idempotente: controlla se esistono dataset prima di rimuoverli
if command -v zfs >/dev/null 2>&1 && command -v docker >/dev/null 2>&1; then
    # Conta dataset Docker ZFS vecchi (hash 64 caratteri)
    OLD_DATASETS=$(zfs list -H -o name -r Storage 2>/dev/null | grep -E "[a-f0-9]{64}" || true)
    
    if [[ -n "$OLD_DATASETS" ]]; then
        DATASET_COUNT=$(echo "$OLD_DATASETS" | wc -l)
        log "  üîß Fix v0.3.0: Trovati $DATASET_COUNT vecchi dataset Docker ZFS"
        log "  üßπ Pulizia dataset vecchi (causano snapshot e rallentamenti)..."
        
        # Verifica che Docker usi overlay2 prima di pulire
        CURRENT_DRIVER=$(docker info 2>/dev/null | grep "Storage Driver" | awk '{print $3}' || echo "unknown")
        
        if [[ "$CURRENT_DRIVER" == "overlay2" ]]; then
            log "  ‚úì Docker usa overlay2, sicuro pulire dataset ZFS vecchi"
            
            # Ferma container prima di pulire
            log "  ‚è∏Ô∏è  Arresto container..."
            cd "$INSTALL_DIR" && docker compose down 2>/dev/null || true
            
            # Distruggi tutti i dataset Docker ZFS vecchi
            DESTROYED=0
            while IFS= read -r dataset; do
                if [[ -n "$dataset" ]]; then
                    if zfs destroy -r "$dataset" 2>/dev/null; then
                        DESTROYED=$((DESTROYED + 1))
                    fi
                fi
            done <<< "$OLD_DATASETS"
            
            log "  ‚úÖ Rimossi $DESTROYED dataset Docker ZFS vecchi"
            log "  ‚úÖ Snapshot automatiche Docker eliminate"
            
            # Riavvia container
            log "  üîÑ Riavvio container con overlay2..."
            cd "$INSTALL_DIR" && docker compose up -d 2>/dev/null || log "  ‚ö†Ô∏è  Riavvia manualmente: docker compose up -d"
        else
            log "  ‚ö†Ô∏è  Docker usa ancora $CURRENT_DRIVER, non pulisco dataset (applica prima fix v0.2.9)"
        fi
    else
        log "  ‚úì Nessun dataset Docker ZFS vecchio trovato"
    fi
else
    log "  ‚ÑπÔ∏è  ZFS o Docker non disponibili, skip fix pulizia dataset"
fi

# Fix v0.2.9: Cambia Docker storage driver da ZFS a overlay2
# Idempotente: controlla driver attuale prima di modificare
if command -v docker >/dev/null 2>&1; then
    DOCKER_DRIVER=$(docker info 2>/dev/null | grep "Storage Driver" | awk '{print $3}' || echo "unknown")
    if [[ "$DOCKER_DRIVER" == "zfs" ]]; then
        log "  üîß Fix v0.2.9: Docker usa storage driver ZFS (crea snapshot automatiche)"
        log "  üîÑ Cambio storage driver a overlay2..."
        
        # Ferma Docker
        systemctl stop docker 2>/dev/null || true
        
        # Backup configurazione Docker
        if [[ -f "/etc/docker/daemon.json" ]]; then
            cp "/etc/docker/daemon.json" "/etc/docker/daemon.json.backup-$(date +%Y%m%d_%H%M%S)"
        fi
        
        # Configura overlay2
        mkdir -p /etc/docker
        cat > /etc/docker/daemon.json << 'DOCKERJSONEOF'
{
  "storage-driver": "overlay2",
  "data-root": "/storage/docker"
}
DOCKERJSONEOF
        
        # Riavvia Docker
        systemctl start docker 2>/dev/null || true
        sleep 2
        
        # Verifica nuovo driver
        NEW_DRIVER=$(docker info 2>/dev/null | grep "Storage Driver" | awk '{print $3}' || echo "unknown")
        if [[ "$NEW_DRIVER" == "overlay2" ]]; then
            log "  ‚úÖ Docker storage driver cambiato con successo a overlay2"
            log "  ‚ö†Ô∏è  IMPORTANTE: I container devono essere ricreati!"
            log "     cd /opt/armnas && docker compose down && docker compose up -d"
        else
            log "  ‚ö†Ô∏è  Cambio storage driver non riuscito (driver: $NEW_DRIVER)"
        fi
    else
        log "  ‚úì Docker storage driver gi√† corretto: $DOCKER_DRIVER"
    fi
else
    log "  ‚ÑπÔ∏è  Docker non installato, skip fix storage driver"
fi

# ========================================================================

# Ricarica systemd se sono stati aggiornati servizi
if ls *.service 1> /dev/null 2>&1; then
    log "  Ricarica systemd daemon..."
    systemctl daemon-reload || log "‚ö†Ô∏è  Errore ricarica systemd"
fi

# Aggiorna Docker Compose files (preserva configurazioni utente)
log "üê≥ Verifica docker compose..."
for compose in docker-compose*.yml; do
    if [[ -f "$compose" ]]; then
        # Verifica se il file esiste gi√† (configurazione utente)
        if [[ -f "$INSTALL_DIR/$compose" ]]; then
            log "  ‚ö†Ô∏è  $compose gi√† esistente - preservato (contiene configurazioni utente)"
            # Salva il nuovo template come .example
            cp "$compose" "$INSTALL_DIR/${compose}.example" || log "‚ö†Ô∏è  Errore salvataggio template"
            log "  üìã Nuovo template salvato come ${compose}.example"
        else
            # File non esiste, copia normalmente
            cp "$compose" "$INSTALL_DIR/" || handle_error "Errore nella copia di $compose"
            log "  ‚úÖ Copiato $compose"
        fi
    fi
done

# Aggiorna file VERSION
log "üìã Aggiornamento file VERSION..."
if [[ -f "VERSION" ]]; then
    # Controlla se non stiamo copiando il file su se stesso
    if [[ "$(realpath VERSION)" != "$(realpath $INSTALL_DIR/VERSION)" ]]; then
        cp "VERSION" "$INSTALL_DIR/" || handle_error "Errore nell'aggiornamento del file VERSION"
        NEW_VERSION=$(cat VERSION)
        log "  ‚úÖ Versione aggiornata a: $NEW_VERSION"
    else
        # File gi√† nella posizione corretta
        NEW_VERSION=$(cat VERSION)
        log "  ‚úÖ File VERSION gi√† aggiornato: $NEW_VERSION"
    fi
else
    log "  ‚ö†Ô∏è  File VERSION non trovato nel pacchetto"
fi

# Ripristina configurazioni critiche
log "üîÑ Ripristino configurazioni..."
if [[ -f "$TEMP_CONFIG_DIR/config.py" ]]; then
    cp "$TEMP_CONFIG_DIR/config.py" "$INSTALL_DIR/backend/"
fi

if [[ -f "$TEMP_CONFIG_DIR/armnas.db" ]]; then
    cp "$TEMP_CONFIG_DIR/armnas.db" "$INSTALL_DIR/backend/"
    log "‚úÖ Database utenti ripristinato"
else
    log "‚ö†Ô∏è  Database utenti non trovato - potrebbe essere necessario ricreare gli utenti admin"
fi

# Aggiorna permessi
log "üîê Aggiornamento permessi..."
chown -R www-data:www-data "$INSTALL_DIR" 2>/dev/null || log "‚ö†Ô∏è  Impossibile impostare proprietario www-data"
chmod +x "$INSTALL_DIR"/*.sh 2>/dev/null || true

# Verifica configurazione nginx
log "üîç Verifica configurazione nginx..."
if command -v nginx >/dev/null 2>&1; then
    if nginx -t 2>/dev/null; then
        log "  ‚úÖ Configurazione nginx valida"
    else
        log "  ‚ö†Ô∏è  Configurazione nginx potrebbe avere problemi"
    fi
fi

# Verifica utenti admin
log "üëë Verifica utenti amministratori..."
if [[ -f "$INSTALL_DIR/backend/armnas.db" ]]; then
    # Controlla se ci sono utenti admin nel database
    ADMIN_COUNT=$(sqlite3 "$INSTALL_DIR/backend/armnas.db" "SELECT COUNT(*) FROM users WHERE is_admin = 1;" 2>/dev/null || echo "0")
    if [[ "$ADMIN_COUNT" -gt 0 ]]; then
        log "‚úÖ Trovati $ADMIN_COUNT utenti amministratori"
    else
        log "‚ö†Ô∏è  ATTENZIONE: Nessun utente amministratore trovato!"
        log "   La voce 'Aggiornamenti' potrebbe non apparire nella sidebar."
        log "   Esegui: python3 $INSTALL_DIR/backend/fix_admin_user.py"
    fi
else
    log "‚ö†Ô∏è  Database utenti non trovato"
fi

# Pulizia
log "üßπ Pulizia file temporanei..."
rm -rf "$TEMP_CONFIG_DIR"

# Riavvia i servizi per applicare le modifiche immediatamente
log "üîÑ Riavvio servizi..."

# Riavvia updater service (servizio separato per aggiornamenti)
if systemctl list-unit-files | grep -q "armnas-updater"; then
    systemctl restart armnas-updater || log "‚ö†Ô∏è  Impossibile riavviare armnas-updater"
    sleep 1
    if systemctl is-active --quiet armnas-updater; then
        log "‚úÖ Updater service riavviato"
    fi
fi

# Riavvia backend
if systemctl list-unit-files | grep -q "$SERVICE_NAME"; then
    systemctl restart "$SERVICE_NAME" || log "‚ö†Ô∏è  Impossibile riavviare $SERVICE_NAME"
    sleep 2
    if systemctl is-active --quiet "$SERVICE_NAME"; then
        log "‚úÖ Backend riavviato con la nuova versione"
    else
        log "‚ö†Ô∏è  Backend non √® attivo, controlla i log"
    fi
fi

# Ricarica nginx
if systemctl list-unit-files | grep -q "$NGINX_SERVICE"; then
    systemctl reload "$NGINX_SERVICE" 2>/dev/null || systemctl restart "$NGINX_SERVICE" || log "‚ö†Ô∏è  Impossibile ricaricare nginx"
    if systemctl is-active --quiet "$NGINX_SERVICE"; then
        log "‚úÖ Nginx aggiornato"
    fi
fi

echo ""
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
log "‚úÖ Aggiornamento completato con successo!"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
echo ""
log "üìç Directory installazione: $INSTALL_DIR"
log "üíæ Backup salvato in: $AUTO_BACKUP_PATH"
log "üì¶ Versione installata: $VERSION"
log "üåê Backend e Nginx riavviati"
echo ""
log "üí° Il sistema √® ora aggiornato e funzionante"
log "   Puoi continuare a usare l'interfaccia web normalmente"
echo ""
log "‚ÑπÔ∏è  Si consiglia comunque di riavviare il NAS quando possibile per:"
echo "   - Applicare eventuali aggiornamenti al kernel"
echo "   - Assicurare che tutte le modifiche siano completamente attive"
echo ""
log "üîÑ Per riavviare: Dashboard ‚Üí Riavvia oppure 'reboot'"
echo ""

# Salva log delle migrazioni applicate
log "üìã Salvataggio log migrazioni..."
mkdir -p "$INSTALL_DIR/.migrations"
cat >> "$INSTALL_DIR/.migrations/applied.log" << MIGEOF
$(date -Iseconds) | $PREVIOUS_VERSION -> $VERSION | armnas_update_v${VERSION}.run
MIGEOF
log "‚úÖ Log migrazione salvato"

# Pulizia file .run dalla directory pending-updates
log "üßπ Pulizia pending-updates..."
if [[ -d "$INSTALL_DIR/pending-updates" ]]; then
    # Rimuovi TUTTI i file .run dalla directory pending-updates
    rm -f "$INSTALL_DIR/pending-updates"/*.run 2>/dev/null || true
    log "‚úÖ File .run rimossi da pending-updates"
fi

exit 0
'''
        
        script_file = package_dir / "install.sh"
        with open(script_file, 'w', encoding='utf-8') as f:
            f.write(install_script)
        
        # Rendi eseguibile
        os.chmod(script_file, 0o755)
    
    def _create_archive(self, package_dir):
        """Crea l'archivio tar.gz"""
        print("üóúÔ∏è  Creazione archivio...")
        
        # Conta i file nel pacchetto
        all_files = list(package_dir.rglob('*'))
        print(f"  üìä File totali nel pacchetto: {len(all_files)}")
        
        # Calcola dimensione totale
        total_size = sum(f.stat().st_size for f in all_files if f.is_file())
        print(f"  üìè Dimensione totale: {total_size / (1024*1024):.1f} MB")
        
        archive_path = Path(self.temp_dir) / "package.tar.gz"
        
        with tarfile.open(archive_path, "w:gz") as tar:
            tar.add(package_dir, arcname=".")
        
        # Verifica dimensione archivio
        archive_size = archive_path.stat().st_size
        print(f"  üì¶ Dimensione archivio: {archive_size / (1024*1024):.1f} MB")
        
        return archive_path
    
    def _create_run_file(self, archive_path):
        """Crea il file .run autoinstallante usando makeself se disponibile"""
        print("üîß Creazione file .run...")
        
        run_filename = f"armnas_update_v{self.version}.run"
        run_path = self.output_dir / run_filename
        
        # Prova prima con makeself
        if self._try_makeself(archive_path, run_path):
            print("‚úÖ File .run creato con makeself")
        else:
            print("‚ö†Ô∏è  makeself non disponibile, uso metodo manuale")
            self._create_run_file_manual(archive_path, run_path)
        
        # Crea file info
        self._create_info_file(run_path)
        
        return run_path
    
    def _try_makeself(self, archive_path, run_path):
        """Prova a usare makeself per creare il file .run"""
        try:
            import subprocess
            
            # Verifica se makeself √® disponibile
            result = subprocess.run(['which', 'makeself'], capture_output=True, text=True)
            if result.returncode != 0:
                return False
            
            # Estrai l'archivio in una directory temporanea per makeself
            temp_extract_dir = tempfile.mkdtemp(prefix="makeself_")
            
            try:
                with tarfile.open(archive_path, "r:gz") as tar:
                    tar.extractall(temp_extract_dir)
                
                # Usa makeself per creare il file .run
                makeself_cmd = [
                    'makeself',
                    '--gzip',
                    '--notemp',
                    temp_extract_dir,
                    str(run_path),
                    f"ArmNAS Update v{self.version}",
                    './launch.sh'
                ]
                
                result = subprocess.run(makeself_cmd, capture_output=True, text=True)
                
                if result.returncode == 0:
                    print(f"‚úÖ makeself completato: {result.stdout}")
                    return True
                else:
                    print(f"‚ùå Errore makeself: {result.stderr}")
                    return False
                    
            finally:
                shutil.rmtree(temp_extract_dir, ignore_errors=True)
                
        except Exception as e:
            print(f"‚ùå Errore nell'uso di makeself: {e}")
            return False
    
    def _create_run_file_manual(self, archive_path, run_path):
        """Crea il file .run manualmente (fallback)"""
        # Header dello script migliorato
        header = '''#!/bin/bash
# ArmNAS Auto-installer v{version}
# Generato il {timestamp}

set -e

# Funzione per logging
log() {{
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}}

# Funzione per gestire errori
handle_error() {{
    log "‚ùå ERRORE: $1"
    exit 1
}}

log "üöÄ Avvio installazione ArmNAS v{version}"

# Trova la posizione dell'archivio
ARCHIVE_START_LINE=$(awk '/^__ARCHIVE_BELOW__/ {{print NR + 1; exit 0; }}' "$0")

if [[ -z "$ARCHIVE_START_LINE" ]]; then
    handle_error "Marker archivio non trovato"
fi

log "üì¶ Estrazione archivio..."

# Crea directory temporanea
TEMP_DIR=$(mktemp -d)
if [[ ! -d "$TEMP_DIR" ]]; then
    handle_error "Impossibile creare directory temporanea"
fi

# Funzione di pulizia
cleanup() {{
    log "üßπ Pulizia file temporanei..."
    cd /
    rm -rf "$TEMP_DIR"
}}

# Imposta trap per pulizia automatica
trap cleanup EXIT

# Estrai archivio
tail -n +$ARCHIVE_START_LINE "$0" | tar -xzf - -C "$TEMP_DIR" || handle_error "Errore nell'estrazione dell'archivio"

# Verifica che launch.sh esista
if [[ ! -f "$TEMP_DIR/launch.sh" ]]; then
    handle_error "Script launch.sh non trovato nell'archivio"
fi

# Esegui installazione
log "üîß Esecuzione installazione..."
cd "$TEMP_DIR"
chmod +x launch.sh
./launch.sh "$@"

log "‚úÖ Installazione completata"
exit 0

__ARCHIVE_BELOW__
'''.format(version=self.version, timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        
        # Scrivi il file .run
        with open(run_path, 'wb') as run_file:
            # Header
            run_file.write(header.encode('utf-8'))
            
            # Archivio
            with open(archive_path, 'rb') as archive_file:
                shutil.copyfileobj(archive_file, run_file)
        
        # Rendi eseguibile
        os.chmod(run_path, 0o755)
    
    def _create_info_file(self, run_path):
        """Crea file .info con informazioni sul pacchetto"""
        info_path = Path(str(run_path) + ".info")
        
        # Calcola hash
        sha256_hash = hashlib.sha256()
        with open(run_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256_hash.update(chunk)
        
        info = {
            "version": self.version,
            "filename": run_path.name,
            "size": os.path.getsize(run_path),
            "sha256": sha256_hash.hexdigest(),
            "created": datetime.now().isoformat()
        }
        
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)

def main():
    print("üöÄ Avvio creazione pacchetto ArmNAS...")
    parser = argparse.ArgumentParser(description="Crea pacchetti di aggiornamento ArmNAS")
    parser.add_argument("version", help="Versione del pacchetto (es: 0.1.2)")
    parser.add_argument("--source", "-s", default=".", help="Directory sorgente (default: .)")
    parser.add_argument("--output", "-o", default="./updates", help="Directory output (default: ./updates)")
    parser.add_argument("--changelog", "-c", help="Messaggio di changelog")
    parser.add_argument("--critical", action="store_true", help="Aggiornamento critico")
    
    args = parser.parse_args()
    
    # Verifica che la directory sorgente esista
    if not os.path.exists(args.source):
        print(f"‚ùå Directory sorgente non trovata: {args.source}")
        sys.exit(1)
    
    # Crea il builder
    builder = UpdatePackageBuilder(args.version, args.output)
    
    try:
        # Crea il pacchetto
        package_file = builder.create_package(
            source_dir=args.source,
            changelog=args.changelog,
            critical=args.critical
        )
        
        print(f"\nüéâ Pacchetto creato con successo!")
        print(f"üìÅ File: {package_file}")
        print(f"üìã Info: {package_file}.info")
        print(f"\nüí° Per installare: sudo bash {package_file}")
        
    except Exception as e:
        print(f"‚ùå Errore durante la creazione del pacchetto: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()